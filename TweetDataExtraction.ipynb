{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60a1667",
   "metadata": {},
   "source": [
    "# Twitter API Data Extraction\n",
    "\n",
    "Connect to twitter API, extract tweets using key words, hashtags, etc.\n",
    "\n",
    "To extract data via the twitter API, follow these steps:\n",
    "\n",
    "1. Sign up for twitter (if you already have an account, skip this step): https://twitter.com/\n",
    "2. Sign into the twitter developer site: https://developer.twitter.com/en\n",
    "3. Follow the site's instructions to locate you API key, secret, and bearer token. Save these as environment variables on your computer. Name each variable:\n",
    "\n",
    "    1. API Key: api_key_twitter\n",
    "    2. API Secret: api_secret_twitter\n",
    "    3. Bearer Token: api_bearer_token_twitter\n",
    "\n",
    "Once your environment variables have been created, follow the steps outlined in the code comments (within each cell) to pull tweets from the twitter API!\n",
    "\n",
    "NOTE: Read the following API documentation for details regarding the GET tweets API request used in this notebook:\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/lookup/api-reference/get-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71568e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter API credentials stored in environment variables\n",
    "api_key = os.environ.get('api_key_twitter')\n",
    "api_key_secret = os.environ.get('api_secret_twitter')\n",
    "bearer_token = os.environ.get('api_bearer_token_twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create headers for requests\n",
    "headers = {\"Authorization\": f\"Bearer {bearer_token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6520d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to send GET request from TWEETS\n",
    "\n",
    "def tweet_search(query, header, next_token=None, max_results=100):\n",
    "    '''\n",
    "    Parameters:\n",
    "        max_results = integer 10 to 100\n",
    "        header = bearer token --> {\"Authorization\": \"Bearer {bearer_token}\"}\n",
    "        query = the hashtag/keyword we're searching for --> example: #queensfuneral\n",
    "    '''\n",
    "    \n",
    "    param = {'query': query,\n",
    "             'max_results': max_results,\n",
    "             'next_token': {next_token},\n",
    "             'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "             'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "             'expansions': 'author_id,geo.place_id',\n",
    "             'user.fields': 'location'}\n",
    "    \n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/recent\", headers=header, params=param)\n",
    "        \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "        \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655ffc8",
   "metadata": {},
   "source": [
    "\n",
    "# Retrieve Tweets using hashtag\n",
    "\n",
    "Follow the cells to pull tweets containing specified hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ENTER HASHTAG HERE #####\n",
    "\n",
    "# enter hashtag in the 'tag' variable\n",
    "# if you want to test out a new hashtag, change the 'tag' variable and re-run this cell, then run the next cell \n",
    "\n",
    "tag = 'queenelizabeth'\n",
    "hashtag = '#' + tag\n",
    "\n",
    "# determines the number of loops (API calls) to make. total number of tweets pulled per run is MAX 100*loops\n",
    "loops = 10\n",
    "\n",
    "# new_token variable used by API to ensure you aren't receiving duplicate tweets, i.e., tweets you already received with \n",
    "# previous API calls.\n",
    "\n",
    "##### DO NOT CHANGE #####\n",
    "new_token = None\n",
    "result = []\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c246b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to pull some tweets\n",
    "# NOTE: sometimes the API sends an error when you've made to many consecutive requests. when this happens, you can just\n",
    "# re-run this cell\n",
    "# If 'KeyError: next_token' is returned, it means there are no more tweets matching the hashtag\n",
    "\n",
    "for number in range(loops):\n",
    "\n",
    "    data = tweet_search(query=hashtag, max_results=100, header=headers, next_token=new_token)\n",
    "    result += data['data']\n",
    "    new_token = data['meta']['next_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tweets were pulled?\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb462154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample of the tweets we received\n",
    "tweets_df = pd.DataFrame(result)\n",
    "display(tweets_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd38bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique authors?\n",
    "print(len(tweets_df['author_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7447a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tweets with location data?\n",
    "print(len(tweets_df)-len(tweets_df[tweets_df['geo'].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64decc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into json file\n",
    "tw = json.dumps(result, indent=4)\n",
    "with open(f\"data/twitter_data_{tag}.json\", \"w\") as outfile:\n",
    "    outfile.write(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99afbc",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After the twitter data was extracted, our team needed enrich the data by retrieving geolocation data and then pre-process the data (cleaning, feature engineering, etc.). These activities are covered in subsequent notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
